{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from ipywidgets import interact, fixed\n",
    "from moviepy.editor import VideoFileClip\n",
    "from collections import deque\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "Minv = None\n",
    "\n",
    "# Make a list of calibration images\n",
    "files = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "images =[]\n",
    "for fname in files:\n",
    "    #read in image\n",
    "    img = mpimg.imread(fname)\n",
    "    # Find the chessboard corners\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        images.append(img)\n",
    "        # Draw the corners\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints,\\\n",
    "                                imgpoints, img.shape[0:2], None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    # Use cv2.calibrateCamera() and cv2.undistort()\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Color/gradient threshold functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def color_gradient_threshold(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    # scale up image\n",
    "    combined_binary *= 255\n",
    "    return color_binary, combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def perspective_transform(img):\n",
    "    image_size = (img.shape[1], img.shape[0])\n",
    "    points_src = [[565,460],[710,460],[1200,718],[250,718]]\n",
    "    src = np.float32(points_src)\n",
    "    pts = np.array(points_src, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    img_src_pts = img.copy()\n",
    "    cv2.polylines(img_src_pts,[pts],True,(255,0,0), 2)\n",
    "\n",
    "    offsetx = 330\n",
    "    offsety = 0\n",
    "    points_dst = [[offsetx, offsety], [image_size[0]-offsetx, offsety], [image_size[0]-offsetx, image_size[1]-offsety], [offsetx, image_size[1]-offsety]]\n",
    "    dst = np.float32(points_dst)\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(img, M, image_size, flags=cv2.INTER_LINEAR)\n",
    "    # region of interest\n",
    "    warped[:, :int(2*warped.shape[0]/9)]=0\n",
    "    warped[:, -int(2*warped.shape[0]/9):]=0\n",
    "    warped_dst_pts = warped.copy()\n",
    "    pts = np.array(points_dst, np.int32)\n",
    "    pts = pts.reshape((-1,1,2))\n",
    "    warped_dst_pts = cv2.polylines(warped_dst_pts,[pts],True,(255,0,0), 2)\n",
    "    return  warped, Minv, img_src_pts, warped_dst_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pipeline_test(image):\n",
    "    undistorted = cal_undistort(image, objpoints, imgpoints)\n",
    "    img = undistorted.copy()\n",
    "    color_binary, combined_binary = color_gradient_threshold(img)\n",
    "    img = cv2.cvtColor(combined_binary, cv2.COLOR_GRAY2BGR)\n",
    "    binary_warped, Minv, img_src_pts, warped_dst_pts = perspective_transform(img)\n",
    "    return undistorted, binary_warped, Minv, img_src_pts, warped_dst_pts\n",
    "\n",
    "def warp_thresh(image):\n",
    "    global Minv\n",
    "    undistorted, binary_warped, Minv, _, _ = pipeline_test(image)\n",
    "    return undistorted, binary_warped\n",
    "\n",
    "def pipeline(image):\n",
    "    global Minv\n",
    "    undistorted, binary_warped, Minv, _, _ = pipeline_test(image)\n",
    "    return binary_warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Detect lane lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Line class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n = 15 # number of historic data cells\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = deque([], maxlen = n)\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.recent_fits = deque([], maxlen = n)\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None\n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "left = Line()\n",
    "right = Line()\n",
    "max_distance = 2.8\n",
    "max_rel_fitx = 0.15\n",
    "n_avg = 8\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "\n",
    "def find_lanes(binary_warped, nwindows = 9, margin = 100, minpix = 50):\n",
    "    binary_warped = cv2.cvtColor(binary_warped, cv2.COLOR_BGR2GRAY)\n",
    "    image_size = (img.shape[1], img.shape[0])\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    #nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and5 left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "        \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # update right lane\n",
    "    if len(right.recent_fits) == 0:\n",
    "        right.detected = True\n",
    "        right.recent_xfitted.append(right_fitx)\n",
    "        right.recent_fits.append(right_fit)\n",
    "        right.current_fit = right_fit\n",
    "        right.best_fit = right_fit\n",
    "        right.bestx = right_fitx\n",
    "    else:\n",
    "        right.line_base_pos = (right_fit[0]*y_eval**2 + right_fit[1]*y_eval \\\n",
    "                               + right_fit[2] - 640.0)*3.7/600.0\n",
    "        right.diffs = right_fitx - right.bestx\n",
    "        rel_diff = np.linalg.norm(right.diffs)/np.linalg.norm(right.bestx)\n",
    "        if abs(right.line_base_pos) <= max_distance \\\n",
    "                    and rel_diff < max_rel_fitx :\n",
    "            right.detected = True\n",
    "            right.recent_xfitted.append(right_fitx)\n",
    "            right.bestx = np.average(np.asarray(right.recent_xfitted), 0)\n",
    "            right.recent_fits.append(right_fit)\n",
    "            right.best_fit = np.average(np.array(right.recent_fits), 0)\n",
    "            right.current_fit = right_fit\n",
    "        else:\n",
    "            right.detected = False\n",
    "            right.recent_fits.pop()\n",
    "            right.recent_xfitted.pop()\n",
    "            if len(right.recent_fits) > 0:\n",
    "                right.bestx = np.average(np.asarray(right.recent_xfitted)[-n_avg:], 0)\n",
    "                right.best_fit = np.average(np.array(right.recent_fits)[-n_avg:], 0)\n",
    "                right.current_fit = right.best_fit\n",
    "        right.allx = rightx\n",
    "        right.ally = righty\n",
    "        right_fit = right.best_fit\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2] \n",
    "            \n",
    "    # update left lane\n",
    "    if len(left.recent_fits) == 0:\n",
    "        left.detected = True\n",
    "        left.recent_xfitted.append(left_fitx)\n",
    "        left.recent_fits.append(left_fit)\n",
    "        left.current_fit = left_fit\n",
    "        left.best_fit = left_fit\n",
    "        left.bestx = left_fitx\n",
    "    else:\n",
    "        left.line_base_pos = (left_fit[0]*720.0**2 + left_fit[1]*720.0 \\\n",
    "                               + left_fit[2] - 640.0)*3.7/600.0\n",
    "        left.diffs = left_fitx - left.bestx\n",
    "        rel_diff = np.linalg.norm(left.diffs)/np.linalg.norm(left.bestx)\n",
    "        if abs(left.line_base_pos) <= max_distance \\\n",
    "                    and rel_diff < max_rel_fitx :\n",
    "            left.detected = True\n",
    "            left.recent_xfitted.append(left_fitx)\n",
    "            left.bestx = np.average(np.asarray(left.recent_xfitted), 0)\n",
    "            left.recent_fits.append(left_fit)\n",
    "            left.best_fit = np.average(np.array(left.recent_fits), 0)\n",
    "            left.current_fit = left_fit\n",
    "        else:\n",
    "            left.detected = False\n",
    "            left.recent_fits.pop()\n",
    "            left.recent_xfitted.pop()\n",
    "            if len(left.recent_fits) > 0:\n",
    "                left.bestx = np.average(np.asarray(left.recent_xfitted)[-n_avg:], 0)\n",
    "                left.best_fit = np.average(np.array(left.recent_fits)[-n_avg:], 0)\n",
    "                left.current_fit = left.best_fit\n",
    "        left.allx = leftx\n",
    "        left.ally = lefty\n",
    "        left_fit = left.best_fit\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2] \n",
    "                        \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]]\\\n",
    "        = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]]\\\n",
    "        = [0, 0, 255]\n",
    "        \n",
    "    warped_lanes = np.zeros_like(out_img, dtype = np.uint8)\n",
    "    l_points = np.array([left_fitx, ploty], dtype = np.int32).transpose()\n",
    "    r_points = np.flipud(np.array([right_fitx, ploty], dtype = np.int32).transpose())\n",
    "    points = np.hstack(([l_points], [r_points]))\n",
    "    color_fit_lines = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    cv2.polylines(color_fit_lines, [l_points], 0, (255, 0, 0), 4)\n",
    "    cv2.polylines(color_fit_lines, [r_points], 0, (0, 0, 255), 4)\n",
    "    cv2.fillPoly(warped_lanes, points, (0, 255, 0))\n",
    "    result = cv2.warpPerspective(warped_lanes, Minv, image_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    #right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    left.radius_of_curvature = left_curverad\n",
    "    right.radius_of_curvature = right_curverad\n",
    "   \n",
    "    lane_center = (left_fitx[image_size[1]-1] + right_fitx[image_size[1]-1])/2.0\n",
    "    image_center = 1280/2.0\n",
    "    line_base_pos = (lane_center - image_center)*xm_per_pix\n",
    "    left.line_base_pos = line_base_pos\n",
    "    right.line_base_pos = line_base_pos\n",
    "    str1 = str('Left radius of curvature: '+str(round(left_curverad/1000))+'km')\n",
    "    cv2.putText(result,str1,(400,650), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3 ,cv2.LINE_AA)\n",
    "    str2 = str('Right radius of curvature: '+str(round(right_curverad/1000))+'km')\n",
    "    cv2.putText(result,str2,(400,700), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3, cv2.LINE_AA)\n",
    "    str3 = str('Distance from center: '+\"{0:.1f}\".format(line_base_pos*100)+'cm')\n",
    "    cv2.putText(result,str3,(400,600), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3, cv2.LINE_AA)\n",
    "    return result, color_fit_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image(in_img):\n",
    "    undistorted, binary_warped = warp_thresh(in_img)\n",
    "    unwarped, color_fit_lines = find_lanes(binary_warped)\n",
    "    out_img = cv2.addWeighted(undistorted, 1, unwarped, 0.3, 0)\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_result.mp4\n",
      "[MoviePy] Writing video project_video_result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [04:20<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_result.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "lane_clip = clip.fl_image(process_image)\n",
    "lane_clip.write_videofile(\"project_video_result.mp4\", audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"360\" controls>\n",
       "  <source src=\"project_video_result.mp4\" type=\"video/mp4\">\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"project_video_result.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
